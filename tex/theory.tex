\section{Theoretical background}

\subsection{Logistic Regression}
The backbone of logistic regression is linear regression, i.e. finding the least-squares solution to an equation system \begin{equation}
    X\theta = b
\end{equation}
given by the normal equations \begin{equation}
    X^TX \theta = X^Tb
\end{equation}
where $X$ is the training data matrix, $\theta$ is the coefficient vector and $b$ is the training output. The parameter vector is then used in the sigmoid function: \begin{align}
    \sigma(z) &= \frac{e^{z}}{1+e^{z}}: \; \mathbb{R}\to [0,1],\\
    z &= x^T \theta,
\end{align}
where $x$ is the testing input. This gives a statistical interpretation of the input vector. In the case of a binary True/False classification, the value of the sigmoid function then determines the class.