\section{Result}

    The method used to evaluate the different models where chosen to be the accuracy as well as the precision and recall of the class "high bike demand".
    The accuracy is defined  by
        \begin{equation*}
            \text{Accuracy} = \frac{n_{correct}}.{n_{tot}},
        \end{equation*}
    and the precision and recall are defined by
        \begin{equation*}
            \text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}
            \qquad
            \text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}.
        \end{equation*}
    Furthermore, a naive model that only guessed  a low demand was compared to the rest of the models. The results of the tests are presented in the table below.
    \begin{table*}[h]
        \begin{center}
            Accuracy of the models
            \\
            \begin{tabular}{|l|c|c|c|}
                \hline
                Model & Accuracy & Precision & Recall \\
                \hline
                LDA & $85\%$ & $53\%$ & $50\%$ \\
                QDA & $87\%$ & $67\%$ & $36\%$ \\
                k-nearest neighbour & $92\%$ & $81\%$ & $70\%$ \\
                Random Forest & $91\%$ & $77\%$ &$71\%$ \\
                Logistic Regression & $90\%$ & $73\%$ &$63\%$ \\ 
                Naive & $83\%$ & $0\%$ & $0\%$ \\
                \hline
            \end{tabular}
        \end{center}
    \end{table*}
    
    To conclude, the random forest and k-nearest neighbour are the best classifiers as they both outpreform linear and quadratic regression on accuracy, precision and recall. Between these two, we see that the kNN method is the best option for this task, because of its higher accuracy and precision score. This choice means a slight loss in income, caused by increasing false negatives, but is thought to be covered by fewer false positives.
    