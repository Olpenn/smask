\section{Result}

The method used to evaluate the different models where simply chosen to be the accuracy defined by:
\begin{equation*}
    \text{accuracy} = \frac{n_{correct}}{n_{tot}}
\end{equation*}
Furthermore, a naive model that only guessed there is a low demand was compared to the rest of the models.
The different models were tested and the accuracy where:
\\
\begin{table*}[h]
    \begin{center}
        Accuracy of the models
        \\
        \begin{tabular}{|l|c|c|c|}
            \hline
            Model & Accuracy & Precision & Recall \\
            \hline
            LDA & $85\%$ & $53\%$ & $50\%$ \\
            QDA & $87\%$ & $67\%$ & $36\%$ \\
            k-nearest neighbour & $92\%$ & $81\%$ & $70\%$ \\
            Random Forest & $91\%$ & $77\%$ &$71\%$ \\
            Naive & $83\%$ & $0\%$ & $0\%$ \\
            \hline
        \end{tabular}
    \end{center}
\end{table*}
Here you can clearly see random forest and k-nearest neighbour are the best classifiers both outpreforming linear and quadratic regression on accuracy, precision and recall.
Out of random forest and kNN the group would proceed with the kNN method, its higher accuracy and precision score out waying the slightly better recall score of random forest. 
This will mean a slight loss in income caused by increasing false negatives but is thought to be covered by fewer false positives.
